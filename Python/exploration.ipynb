{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: z.shen1@tue.nl, f.corradi@tue.nl\n",
    "# Training SpikeVision for DVS 128 dataset\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import wandb\n",
    "from timm.scheduler.step_lr import StepLRScheduler\n",
    "from torch.utils.data import DataLoader, ConcatDataset, random_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_src = \"./results/\"\n",
    "try:\n",
    "    os.mkdir(folder_src)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "dataset = \"DVS128\"\n",
    "folder = folder_src + f\"{dataset}/\"\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from SV import SpikeVision\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from torch.amp import GradScaler, autocast\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = GradScaler()\n",
    "time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "batch_size = 16\n",
    "layers = 1\n",
    "in_channels = 2\n",
    "train_threshold = False\n",
    "image_size = 128\n",
    "dataset_classes = 11\n",
    "num_epochs = 200\n",
    "time_steps = 8\n",
    "embed_dim = 32\n",
    "threshold = [128/128, 128/128, 128/128]\n",
    "pooling_state = \"1111\"\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "precision_epochs = num_epochs\n",
    "precision_bits = 8\n",
    "load = False\n",
    "train_loss_fn, test_loss_fn = criteria, criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulating\n",
    "event_per_map = 15000\n",
    "def integrate_fixed_events(events, H, W, events_per_map = event_per_map):\n",
    "    t, x, y, p = (events[key] for key in ('t', 'x', 'y', 'p'))\n",
    "    total_events = len(t)\n",
    "    num_maps = int(np.ceil(total_events / events_per_map))\n",
    "    frames = np.zeros([num_maps, 2, H, W], dtype=np.float32)\n",
    "\n",
    "    for i in range(num_maps):\n",
    "        start_index = i * events_per_map\n",
    "        end_index = min((i + 1) * events_per_map, total_events)\n",
    "        for j in range(start_index, end_index):\n",
    "            if p[j] == 1:\n",
    "                frames[i, 1, y[j], x[j]] += 1\n",
    "            else:\n",
    "                frames[i, 0, y[j], x[j]] += 1\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = DVS128Gesture(\n",
    "    \"../data/DVS128/\",\n",
    "    train=True,\n",
    "    data_type=\"frame\",\n",
    "    custom_integrate_function=integrate_fixed_events\n",
    ")\n",
    "dataset_test = DVS128Gesture(\n",
    "    \"../data/DVS128/\",\n",
    "    train=False,\n",
    "    data_type=\"frame\", \n",
    "    custom_integrate_function=integrate_fixed_events\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "combined_dataset = ConcatDataset([dataset_train, dataset_test])\n",
    "train_size = int(0.8 * len(combined_dataset))\n",
    "test_size = len(combined_dataset) - train_size\n",
    "generator = torch.Generator()\n",
    "manual_seed = np.random.randint(low=0, high=100)\n",
    "print(manual_seed)\n",
    "generator.manual_seed(manual_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = SpikeVision(\n",
    "    dataset=dataset,\n",
    "    image_size_h=image_size,\n",
    "    image_size_w=image_size,\n",
    "    input_channels=in_channels,\n",
    "    num_classes=dataset_classes,\n",
    "    embed_dims=embed_dim,\n",
    "    threshold_head=threshold[0],\n",
    "    threshold_conv=threshold[1],\n",
    "    threshold_scre=threshold[2],\n",
    "    depths=layers,\n",
    "    pooling_state=pooling_state,\n",
    "    train_threshold=train_threshold,\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params = [p for p in model.parameters() if p.requires_grad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the 'key' with your own key\n",
    "wandb.login(key='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = folder + f\"model_{dataset}_embeddim_{embed_dim}_depth_{layers}_{time}.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "train_eval_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "def train(path):\n",
    "\n",
    "    # Initialize wandb\n",
    "    with wandb.init() as run:\n",
    "        config = wandb.config\n",
    "\n",
    "        # Set default hyperparameters if not provided in sweep config\n",
    "        if not hasattr(config, 'num_epochs'):\n",
    "            config.num_epochs = 250\n",
    "        if not hasattr(config, 'batch_size'):\n",
    "            config.batch_size = 20\n",
    "        if not hasattr(config, 'learning_rate'):\n",
    "            config.learning_rate = 1e-3\n",
    "        if not hasattr(config, 'embed_dims'):\n",
    "            config.embed_dims = 256\n",
    "        if not hasattr(config, 'time_steps'):\n",
    "            config.time_steps = 16\n",
    "        if not hasattr(config, 'thresholds'):\n",
    "            config.thresholds = [128/128, 128/128, 128/128]\n",
    "        if not hasattr(config, 'pooling_stat'):\n",
    "            config.pooling_stat = \"1111\"\n",
    "        if not hasattr(config, 'layers'):\n",
    "            config.layers = 2\n",
    "        if not hasattr(config, 'train_threshold'):\n",
    "            config.train_threshold = False\n",
    "        if not hasattr(config, 'image_size'):\n",
    "            config.image_size = 128\n",
    "        if not hasattr(config, 'image_size_w'):\n",
    "            config.image_size_w = 128\n",
    "        if not hasattr(config, 'in_channels'):\n",
    "            config.in_channels = 2\n",
    "        if not hasattr(config, 'num_classes'):\n",
    "            config.num_classes = 11\n",
    "        if not hasattr(config, 'manual_seed'):\n",
    "            config.manual_seed = 49\n",
    "        # Create dataloaders\n",
    "        dataset_train, dataset_test = random_split(combined_dataset, [train_size, test_size], generator=generator)\n",
    "        def custom_collate_fn(batch):\n",
    "            max_timesteps = time_steps\n",
    "            padded_batch = []\n",
    "\n",
    "            for item in batch:\n",
    "                data, label = item\n",
    "                if isinstance(data, np.ndarray):\n",
    "                    data = torch.from_numpy(data).float()\n",
    "\n",
    "                current_timesteps = data.size(0)\n",
    "\n",
    "                if current_timesteps < max_timesteps:\n",
    "                    padding_size = (0, 0, 0, 0, 0, 0, 0, max_timesteps - current_timesteps)\n",
    "                    padded_data = torch.nn.functional.pad(data, pad=padding_size, mode='constant', value=0)\n",
    "                else:\n",
    "                    padded_data = data[:max_timesteps]\n",
    "\n",
    "                padded_batch.append((padded_data, label))\n",
    "\n",
    "            return torch.utils.data.dataloader.default_collate(padded_batch)\n",
    "        train_loader = DataLoader(\n",
    "            dataset_train,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=custom_collate_fn,\n",
    "            num_workers=8,\n",
    "            pin_memory=False,\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            dataset_test,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=custom_collate_fn,\n",
    "            num_workers=8,\n",
    "            pin_memory=False,\n",
    "        )\n",
    "\n",
    "        if load:\n",
    "            model.load_state_dict(torch.load(path))\n",
    "        \n",
    "        acc_state = 0\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            train_acc = 0\n",
    "            train_loss_sum = 0\n",
    "            optimizer.zero_grad()\n",
    "            predictions = []\n",
    "\n",
    "            if epoch == 0:\n",
    "                print(f\"{len(train_loader)} batches in one epoch.\")\n",
    "            \n",
    "            for i, (images, labels) in tqdm(enumerate(train_loader)):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                model.train()\n",
    "\n",
    "                with autocast(device_type=f\"{device}\"):\n",
    "                    outputs = model(images)\n",
    "                    loss = train_loss_fn(outputs, labels)\n",
    "                    prediction = outputs.argmax(axis=1)\n",
    "                scaler.scale(loss).backward()\n",
    "                train_loss_sum += loss.item()\n",
    "\n",
    "                train_acc += (prediction == labels).sum().item()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            if (epoch >= precision_epochs):\n",
    "                low_precision_state = low_precision(model.state_dict(), precision=low_precision)\n",
    "                if epoch == precision_epochs:\n",
    "                    torch.save(model.state_dict(), path)\n",
    "                    path = folder + \"low_precision_model\" + path\n",
    "                    for param in optimizer.param_groups:\n",
    "                        param['lr'] = 1e-3\n",
    "                model.load_state_dict(low_precision_state)\n",
    "                model.to(device)\n",
    "            \n",
    "            test_acc, train_eval_acc, test_loss = test(model, test_loader, train_loader)\n",
    "            if test_acc >= acc_state:\n",
    "                acc_state = test_acc\n",
    "                torch.save(model.state_dict(), path)\n",
    "                print(\"Checkpoint saved.\")\n",
    "            \n",
    "            train_loss = train_loss_sum / len(train_loader)\n",
    "            train_loss_list.append(train_loss)\n",
    "            test_loss_list.append(test_loss)\n",
    "            scheduler.step(epoch)\n",
    "            train_accuracy = train_acc / len(train_loader.dataset)\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"test_loss\": test_loss,\n",
    "                \"test_accuracy\": test_acc,\n",
    "                \"learning_rate\": config.learning_rate,\n",
    "                \"batch_size\": config.batch_size,\n",
    "                \"time_steps\": config.time_steps,\n",
    "                \"embed_dims\": config.embed_dims,\n",
    "                \"num_epoch\": config.num_epochs,\n",
    "                \"thresholds\": config.thresholds,\n",
    "                \"pooling_stat\": config.pooling_stat,\n",
    "                \"layers\": config.layers,\n",
    "                \"train_threshold\": config.train_threshold,\n",
    "                \"manual_seed\": config.manual_seed,\n",
    "            })\n",
    "\n",
    "            print(f\"Highest test accuracy: {acc_state}\")\n",
    "            print(f\"Epoch: {epoch:3d}, Train loss: {train_loss:.4f}, Train accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "            if epoch + 1 == 20 and test_acc < 73.0:\n",
    "                print(f\"Test accuracy below 73% at epoch 20. Stopping current training run.\")\n",
    "                return  # Ends current `train` function, letting wandb agent start a new run.\n",
    "\n",
    "            # Save best model\n",
    "            if (test_acc > acc_state) and (test_acc > 88):\n",
    "                acc_state = test_acc\n",
    "                # Include configuration parameters in the filename\n",
    "                model_save_path = (\n",
    "                    f\"results/DVS128/highest_model_epoch{epoch+1}_acc{test_acc:.2f}_\"\n",
    "                    f\"lr{config.learning_rate}_bs{config.batch_size}_tsteps{config.time_steps}_\"\n",
    "                    f\"embed{config.embed_dims}_patch{config.patch_size}_ext{config.input_extend}_\"\n",
    "                    f\"seeddb{config.manual_seed}_seeddb_\"\n",
    "                    f\"layers{config.layers}_heads{config.num_heads}_mlp{config.mlp_ratio}.pth\"\n",
    "                )\n",
    "                torch.save(model.state_dict(), model_save_path)\n",
    "                wandb.save(model_save_path)\n",
    "                print(f'New best model saved with test accuracy: {acc_state:.2f}%')\n",
    "\n",
    "            print(f'Training complete. Best test accuracy: {acc_state:.2f}%')\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for i, (images, labels) in enumerate(loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        model.eval()\n",
    "        if len(images.shape) == 3:\n",
    "            images = images.unsqueeze(1)\n",
    "        outputs = model(images)\n",
    "        loss = test_loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        prediction = outputs.argmax(axis=1)\n",
    "        total_correct += (prediction == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    accuracy = total_correct / len(loader.dataset)\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "def test(model, test_loader, train_loader):\n",
    "    model.eval()\n",
    "    test_acc, test_loss = evaluate(model, test_loader)\n",
    "    train_eval_acc, train_eval_loss = evaluate(model, train_loader)\n",
    "\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    print(f'Train eval Loss: {train_eval_loss:.4f}, Train eval Acc: {train_eval_acc:.4f}')\n",
    "    return test_acc, train_eval_acc, test_loss\n",
    "\n",
    "def precision_transfer(x, precision_bits=8, threshold=1.0, max_value=0.5, min_value=-0.5):\n",
    "    x_flat = x.flatten()\n",
    "    step = np.diff(np.linspace(min_value, max_value, num=2**precision_bits)[0:2])\n",
    "    max_value = max_value - step[0]\n",
    "    q_list = np.round(np.linspace(min_value, max_value, num=2**precision_bits), precision_bits - 2)\n",
    "\n",
    "    func = lambda x: q_list[np.abs(q_list - x).argmin()]\n",
    "    q_list = np.array(list(map(func, x_flat)))\n",
    "    q_list = q_list.reshape(x.shape)\n",
    "    return q_list\n",
    "\n",
    "def low_precision(state_dict, precision=8, threshold=1.0, max_value=0.5, min_value=-0.5):\n",
    "    for key in state_dict.keys():\n",
    "        if \"threshold\" in key:\n",
    "            continue\n",
    "        state_dict[key] = precision_transfer(state_dict[key].cpu().numpy(), precision_bits=precision, threshold=threshold)\n",
    "\n",
    "    return state_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "dataset_train, dataset_test = random_split(combined_dataset, [train_size, test_size], generator=generator)\n",
    "def custom_collate_fn(batch):\n",
    "    max_timesteps = time_steps\n",
    "    padded_batch = []\n",
    "\n",
    "    for item in batch:\n",
    "        data, label = item\n",
    "        if isinstance(data, np.ndarray):\n",
    "            data = torch.from_numpy(data).float()\n",
    "\n",
    "        current_timesteps = data.size(0)\n",
    "\n",
    "        if current_timesteps < max_timesteps:\n",
    "            padding_size = (0, 0, 0, 0, 0, 0, 0, max_timesteps - current_timesteps)\n",
    "            padded_data = torch.nn.functional.pad(data, pad=padding_size, mode='constant', value=0)\n",
    "        else:\n",
    "            padded_data = data[:max_timesteps]\n",
    "\n",
    "        padded_batch.append((padded_data, label))\n",
    "\n",
    "    return torch.utils.data.dataloader.default_collate(padded_batch)\n",
    "train_loader = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    num_workers=8,\n",
    "    pin_memory=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    num_workers=8,\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scheduler(args, optimizer):\n",
    "    num_epochs = args.epochs\n",
    "\n",
    "    if getattr(args, 'lr_noise', None) is not None:\n",
    "        lr_noise = getattr(args, 'lr_noise')\n",
    "        if isinstance(lr_noise, (list, tuple)):\n",
    "            noise_range = [n * num_epochs for n in lr_noise]\n",
    "            if len(noise_range) == 1:\n",
    "                noise_range = noise_range[0]\n",
    "        else:\n",
    "            noise_range = lr_noise * num_epochs\n",
    "    else:\n",
    "        noise_range = None\n",
    "    noise_args = dict(\n",
    "        noise_range_t=noise_range,\n",
    "        noise_pct=getattr(args, 'lr_noise_pct', 0.67),\n",
    "        noise_std=getattr(args, 'lr_noise_std', 1.),\n",
    "        noise_seed=getattr(args, 'seed', 42),\n",
    "    )\n",
    "    cycle_args = dict(\n",
    "        cycle_mul=getattr(args, 'lr_cycle_mul', 1.),\n",
    "        cycle_decay=getattr(args, 'lr_cycle_decay', 0.1),\n",
    "        cycle_limit=getattr(args, 'lr_cycle_limit', 1),\n",
    "    )\n",
    "    lr_scheduler = StepLRScheduler(\n",
    "        optimizer,\n",
    "        decay_t=args.decay_epochs,\n",
    "        decay_rate=args.decay_rate,\n",
    "        warmup_lr_init=args.warmup_lr,\n",
    "        warmup_t=args.warmup_epochs,\n",
    "        **noise_args,\n",
    "    )\n",
    "\n",
    "\n",
    "    return lr_scheduler, num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "learning_rate = 1e-3\n",
    "\n",
    "cooldown = 10\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.epochs = num_epochs\n",
    "        self.sched = 'step'  \n",
    "        self.min_lr = 1e-5\n",
    "        self.warmup_lr = 3e-4\n",
    "        self.warmup_epochs = 20\n",
    "        self.decay_rate = 0.9\n",
    "        self.cooldown_epochs = cooldown\n",
    "        self.lr_noise = [0.6, 0.9]\n",
    "        self.lr_noise_pct = 0.67\n",
    "        self.lr_noise_std = 1.0\n",
    "        self.seed = 42\n",
    "        self.decay_epochs = 20\n",
    "        self.patience_epochs = 5\n",
    "\n",
    "args = Args()\n",
    "\n",
    "optimizer = torch.optim.Adam([{ 'params': base_params}], lr=learning_rate, weight_decay=0)\n",
    "\n",
    "scheduler, num_epochs = create_scheduler(args, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes',  # Bayesian optimization to efficiently explore the hyperparameter space\n",
    "    'metric': {\n",
    "        'name': 'test_accuracy',  # Primary metric to optimize\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'min': 1e-4,\n",
    "            'max': 1e-3  # Learning rate range\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [12,16]  # Possible batch sizes\n",
    "        },\n",
    "        'time_steps': {\n",
    "            'values': [16]  # Add more values if needed\n",
    "        },\n",
    "        'embed_dims': {\n",
    "            'values': [256]  # Common options for embedding dimensions\n",
    "        },\n",
    "        'patch_size': {\n",
    "            'values': [8]  # Example values for patch sizes\n",
    "        },\n",
    "        'num_epoch': {\n",
    "            'values': [250]  # Experiment with different training durations\n",
    "        },\n",
    "        'thresholds': {\n",
    "            'values': [\n",
    "                [128/128, 128/128, 128/128],  # Current configuration\n",
    "                [64/128, 64/128, 64/128]    # Example alternative\n",
    "                #[192/128, 192/128, 192/128]  # Another example\n",
    "            ]\n",
    "        },\n",
    "        'pooling_stat': {\n",
    "            'values': [\"1111\"]  # Example configurations\n",
    "        },\n",
    "        'manual_seed': {\n",
    "            'min': 1,\n",
    "            'max': 250,  # Define the range of seeds to explore\n",
    "            'distribution': 'int_uniform'  # Ensure seeds are integers\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wandb run\n",
    "wandb.init(project=\"Zhanbodraft\", config={\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_epochs\": 50,\n",
    "    \"embed_dim\": 256,\n",
    "    \"alpha\": 0.9,\n",
    "    \"v_threshold\": 0.1,\n",
    "    \"scheduler_type\": \"cosine\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"Zhanbodraft\")\n",
    "wandb.agent(sweep_id, function=train(path=path), count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
